Owner: Ganesh Joshi

1. install kubectl
https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/#install-kubectl-binary-with-curl-on-linux

2. install eksctl
curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
sudo mv /tmp/eksctl /usr/local/bin
eksctl version

3. install aws cli

curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
apt install unzip
unzip awscliv2.zip
./aws/install
# aws --version
aws-cli/2.15.21 Python/3.11.6 Linux/5.15.0-1048-aws exe/x86_64.ubuntu.20 prompt/off
#

4. Now configure aws cli using below command.
# aws configure
AWS Access Key ID [None]: AKI*********FOYOQ
AWS Secret Access Key [None]: SDKZ3******KL************wqBYM1
Default region name [None]: us-east-2
Default output format [None]:
root@eks:~#

5. Now create eks via command line.

root@eks:~# eksctl create cluster --name demo-cluster --region us-east-2 --fargate
//it will take 15 to 20 minute to create complete cluster with public and private subnet.
------------------------------------------------------------------------------------------
Note: Useully, whenever a aws service wants to talk to other aws service or whenever a resource like we have created an application in ec2 and this application
wants to talk to s3 bucket we need an IAM role. similearly whenever you create kubernetes pod, you can attach or you can integrate that IAM Role with your
kubernetes service account so that you can talk to any other aws services.

6. Now it has been installed. You can check from the AWS User Interface.
Note: in compute section of created eks, there one option called Fargate profiles and we have one profile name fp-default that is connected with default,kube-system namespace, 
that means we can only create pod in only these 2 namespace. 
So if we want to deploy pods in any another namespaces so we will have and additional Fargate profile that we can create by clicking on "Add Fargate profile" but we will do this from
command line(8th step).

7. 
root@eks:~# aws eks update-kubeconfig --name demo-cluster --region us-east-2
Added new context arn:aws:eks:us-east-2:381491818383:cluster/demo-cluster to /root/.kube/config
root@eks:~#

root@eks:~# kubectl get node
NAME                                                   STATUS   ROLES    AGE   VERSION
fargate-ip-192-168-164-13.us-east-2.compute.internal   Ready    <none>   11m   v1.27.9-eks-680e576
fargate-ip-192-168-181-63.us-east-2.compute.internal   Ready    <none>   11m   v1.27.9-eks-680e576
root@eks:~#

8. Create Fargate profile
root@eks:~# eksctl create fargateprofile \
>     --cluster demo-cluster \
>     --region us-east-2 \
>     --name alb-sample-app \
>     --namespace game-2048
2024-02-19 21:03:48 [ℹ]  creating Fargate profile "alb-sample-app" on EKS cluster "demo-cluster"
2024-02-19 21:04:05 [ℹ]  created Fargate profile "alb-sample-app" on EKS cluster "demo-cluster"
root@eks:~#
//So just to verify go to AWS dashboard>eks>demo-cluster>cluster>scroll down> you will se now two fargate profile.
Note: so every time if you want to do your deployment in any new namespace so first you will have to create faragate profile for that namespace.
whereas if you are using ec2 not fargate then this step is not required.

9. lets deploy the app.
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.5.4/docs/examples/2048/2048_full.yaml

Remember: this yaml is createing namespace,pod(5),Service and Ingress. but this is not creating ingress controller.

//let's verify.
root@eks:~#  kubectl get po -n game-2048
NAME                               READY   STATUS    RESTARTS   AGE
deployment-2048-7ccfd8fdd6-5xw67   1/1     Running   0          15m
deployment-2048-7ccfd8fdd6-cckmx   1/1     Running   0          15m
deployment-2048-7ccfd8fdd6-rfbj8   1/1     Running   0          15m
deployment-2048-7ccfd8fdd6-s94fh   1/1     Running   0          15m
deployment-2048-7ccfd8fdd6-wqkqf   1/1     Running   0          15m
root@eks:~# kubectl get svc -n game-2048
NAME           TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
service-2048   NodePort   10.100.160.234   <none>        80:31747/TCP   16m
root@eks:~# kubectl get ingress -n game-2048
NAME           CLASS   HOSTS   ADDRESS   PORTS   AGE
ingress-2048   alb     *                 80      16m
root@eks:~#

10. Create ingress controller.
ingress controller > ingress-2048 > load balancer > target group >port.
this all will take care by ingress controller.

10.1. first create IAM OIDC provider.
root@eks:~# eksctl utils associate-iam-oidc-provider --cluster demo-cluster --approve
2024-02-19 21:33:31 [ℹ]  will create IAM Open ID Connect provider for cluster "demo-cluster" in "us-east-2"
2024-02-19 21:33:31 [✔]  created IAM Open ID Connect provider for cluster "demo-cluster" in "us-east-2"
root@eks:~#

10.2. setup alb add on
root@eks:~# curl -O https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.5.4/docs/install/iam_policy.json
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  8386  100  8386    0     0  83029      0 --:--:-- --:--:-- --:--:-- 83029
root@eks:~# aws iam create-policy \
>     --policy-name AWSLoadBalancerControllerIAMPolicy \
>     --policy-document file://iam_policy.json
{
    "Policy": {
        "PolicyName": "AWSLoadBalancerControllerIAMPolicy",
        "PolicyId": "ANPAVRUVPF6HYMBVIY6RO",
        "Arn": "arn:aws:iam::381491818383:policy/AWSLoadBalancerControllerIAMPolicy",
        "Path": "/",
        "DefaultVersionId": "v1",
        "AttachmentCount": 0,
        "PermissionsBoundaryUsageCount": 0,
        "IsAttachable": true,
        "CreateDate": "2024-02-19T21:37:45+00:00",
        "UpdateDate": "2024-02-19T21:37:45+00:00"
    }
}
root@eks:~#
-----
10.3. Create service account.
Now we will attach this role to the service account of the pod, whenever the pod is running, the pod will have a service acccount and for this service account
you need to role attache so that it can integrate with other service account.

root@eks:~# eksctl create iamserviceaccount \
>   --cluster=demo-cluster \
>   --namespace=kube-system \
>   --name=aws-load-balancer-controller \
>   --role-name AmazonEKSLoadBalancerControllerRole \
>   --attach-policy-arn=arn:aws:iam::381491818383:policy/AWSLoadBalancerControllerIAMPolicy \
>   --approve
2024-02-19 21:44:51 [ℹ]  1 iamserviceaccount (kube-system/aws-load-balancer-controller) was included (based on the include/exclude rules)
2024-02-19 21:44:51 [!]  serviceaccounts that exist in Kubernetes will be excluded, use --override-existing-serviceaccounts to override
2024-02-19 21:44:51 [ℹ]  1 task: {
    2 sequential sub-tasks: {
        create IAM role for serviceaccount "kube-system/aws-load-balancer-controller",
        create serviceaccount "kube-system/aws-load-balancer-controller",
    } }2024-02-19 21:44:51 [ℹ]  building iamserviceaccount stack "eksctl-demo-cluster-addon-iamserviceaccount-kube-system-aws-load-balancer-controller"
2024-02-19 21:44:51 [ℹ]  deploying stack "eksctl-demo-cluster-addon-iamserviceaccount-kube-system-aws-load-balancer-controller"
2024-02-19 21:44:51 [ℹ]  waiting for CloudFormation stack "eksctl-demo-cluster-addon-iamserviceaccount-kube-system-aws-load-balancer-controller"
2024-02-19 21:45:21 [ℹ]  waiting for CloudFormation stack "eksctl-demo-cluster-addon-iamserviceaccount-kube-system-aws-load-balancer-controller"
2024-02-19 21:45:21 [ℹ]  created serviceaccount "kube-system/aws-load-balancer-controller"
root@eks:~#

11. Now create the ALB.
We will use helm chart
wget https://get.helm.sh/helm-v3.9.3-linux-amd64.tar.gz
tar xvf helm-v3.9.3-linux-amd64.tar.gz
sudo mv linux-amd64/helm /usr/local/bin
helm version
helm repo add eks https://aws.github.io/eks-charts
helm repo list
helm repo update eks  //run this command if any new updates are in helm chart

12. install aws-load-balancer-controller

root@eks:~# helm install aws-load-balancer-controller eks/aws-load-balancer-controller -n kube-system --set clusterName=demo-cluster --set serviceAccount.create=false --set serviceAccount.name=aws-load-balancer-controller --set region=us-east-2 --set vpcId=vpc-08ec7e892d71f2fbb
NAME: aws-load-balancer-controller
LAST DEPLOYED: Mon Feb 19 21:54:48 2024
NAMESPACE: kube-system
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
AWS Load Balancer controller installed!
root@eks:~#

13. 
root@eks:~# kubectl get deploy aws-load-balancer-controller -n kube-system
NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
aws-load-balancer-controller   2/2     2            2           4m22s
root@eks:~#

root@eks:~# kubectl get ingress -n game-2048
NAME           CLASS   HOSTS   ADDRESS                                                                   PORTS   AGE
ingress-2048   alb     *       k8s-game2048-ingress2-bcac0b5b37-1158860711.us-east-2.elb.amazonaws.com   80      46m

conclusion: So as devops, its our responsbility to create pod, deployment, service, ingress and one time ingress-controller.


